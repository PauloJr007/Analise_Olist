{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1382c8ad",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[üßæ Inser√ß√£o de Dados](#toc0_)\n",
    "\n",
    "**Este notebook documenta um passo importante do pipeline de dados: a inser√ß√£o das tabelas no banco de dados.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd835702",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [üßæ Inser√ß√£o de Dados](#toc1_)    \n",
    "    - [Importando as Bibliotecas](#toc1_1_1_)    \n",
    "  - [1¬∞ Inser√ß√£o](#toc1_2_)    \n",
    "  - [2¬∞ Inser√ß√£o (Atualiza√ß√£o)](#toc1_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758f191a",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Importando as Bibliotecas](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00addbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text  # Para cria√ß√£o da engine de conex√£o e execu√ß√£o de queries SQL (usando MySQL)\n",
    "import pandas as pd  # Biblioteca para manipula√ß√£o, an√°lise e estrutura√ß√£o de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbada7e",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[1¬∞ Inser√ß√£o](#toc0_)\n",
    "\n",
    "üóÇÔ∏è Fonte dos dados: [Kaggle - Olist Brazilian E-Commerce Public Dataset](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/data)  \n",
    "\n",
    "üí° Justificativa: Por escolha pr√≥pria, decidi importar os dados diretamente para um banco relacional como forma de simular um cen√°rio real, com integra√ß√£o de dados, uso de SQLAlchemy e organiza√ß√£o para consultas futuras.\n",
    "\n",
    "üîç Caracter√≠sticas desta etapa:\n",
    "\n",
    "- Os dados ainda n√£o passaram por nenhuma limpeza ou tratamento  \n",
    "- Cada arquivo `.csv` foi associado √† sua respectiva tabela no banco  \n",
    "- A inser√ß√£o foi realizada via Python + SQLAlchemy, com controle por `chunksize` para evitar sobrecarga  \n",
    "- A conex√£o foi feita localmente, simulando um ambiente produtivo real\n",
    "\n",
    "> Esta etapa marca o in√≠cio do ciclo anal√≠tico, onde os dados sujos s√£o organizados e centralizados. A partir daqui, cada transforma√ß√£o ser√° documentada e justificada nos notebooks seguintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b343e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lendo dados do arquivo: olist_geolocation_dataset.csv para a tabela: olist_geolocation\n",
      "Dados inseridos na tabela olist_geolocation com sucesso.\n",
      "\n",
      "Lendo dados do arquivo: olist_customers_dataset.csv para a tabela: olist_customers\n",
      "Dados inseridos na tabela olist_customers com sucesso.\n",
      "\n",
      "Lendo dados do arquivo: olist_sellers_dataset.csv para a tabela: olist_sellers\n",
      "Dados inseridos na tabela olist_sellers com sucesso.\n",
      "\n",
      "Lendo dados do arquivo: olist_products_dataset.csv para a tabela: olist_products\n",
      "Dados inseridos na tabela olist_products com sucesso.\n",
      "\n",
      "Lendo dados do arquivo: olist_orders_dataset.csv para a tabela: olist_orders\n",
      "Dados inseridos na tabela olist_orders com sucesso.\n",
      "\n",
      "Lendo dados do arquivo: olist_order_items_dataset.csv para a tabela: olist_order_items\n",
      "Dados inseridos na tabela olist_order_items com sucesso.\n",
      "\n",
      "Lendo dados do arquivo: olist_order_payments_dataset.csv para a tabela: olist_order_payments\n",
      "Dados inseridos na tabela olist_order_payments com sucesso.\n",
      "\n",
      "Lendo dados do arquivo: olist_order_reviews_dataset.csv para a tabela: olist_order_reviews\n",
      "Dados inseridos na tabela olist_order_reviews com sucesso.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Caminho base onde est√£o os arquivos CSV\n",
    "base_path = \"C:/Users/Pasta/Olist/Dados/\"\n",
    "\n",
    "# Conex√£o com o MySQL via SQLAlchemy\n",
    "engine = create_engine(\"mysql+mysqlconnector://root:...\")\n",
    "\n",
    "# Mapeamento nome_tabela : nome_arquivo.csv\n",
    "tabelas_arquivos = {\n",
    "    \"olist_geolocation\": \"olist_geolocation_dataset.csv\",\n",
    "    \"olist_customers\": \"olist_customers_dataset.csv\",\n",
    "    \"olist_sellers\": \"olist_sellers_dataset.csv\",\n",
    "    \"olist_products\": \"olist_products_dataset.csv\",\n",
    "    \"olist_orders\": \"olist_orders_dataset.csv\",\n",
    "    \"olist_order_items\": \"olist_order_items_dataset.csv\",\n",
    "    \"olist_order_payments\": \"olist_order_payments_dataset.csv\",\n",
    "    \"olist_order_reviews\": \"olist_order_reviews_dataset.csv\"\n",
    "}\n",
    "\n",
    "for tabela, arquivo in tabelas_arquivos.items():\n",
    "    print(f\"Lendo dados do arquivo: {arquivo} para a tabela: {tabela}\")\n",
    "    caminho_completo = base_path + arquivo\n",
    "    \n",
    "    # Leitura do CSV\n",
    "    df = pd.read_csv(caminho_completo)\n",
    "    \n",
    "    # Insere no banco, em partes para evitar travar\n",
    "    df.to_sql(\n",
    "        name=tabela,\n",
    "        con=engine,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        chunksize=500\n",
    "    )\n",
    "    print(f\"Dados inseridos na tabela {tabela} com sucesso.\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6e4ca1",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[2¬∞ Inser√ß√£o (Atualiza√ß√£o)](#toc0_)\n",
    "\n",
    "üóÇÔ∏è Fonte dos dados: P√≥s-tratamento realizado no notebook [preprocessing.ipynb]\n",
    "\n",
    "üí° Justificativa: Os dados foram atualizados no banco ap√≥s passarem por processos de limpeza e tratamento. Agora est√£o prontos para an√°lises mais robustas e confi√°veis.\n",
    "\n",
    "üîç Caracter√≠sticas desta etapa:\n",
    "\n",
    "- Os dados passaram por etapas de limpeza e pr√©-processamento, como remo√ß√£o de inconsist√™ncias, tratamento de valores nulos e padroniza√ß√£o de formatos\n",
    "- Cada arquivo .csv tratado foi vinculado √† sua respectiva tabela no banco de dados\n",
    "- A inser√ß√£o foi realizada utilizando Python + SQLAlchemy, com controle de chunksize para garantir efici√™ncia e evitar sobrecarga na mem√≥ria\n",
    "- A conex√£o foi feita localmente, simulando um ambiente produtivo real\n",
    "\n",
    "> Esta etapa representa a transi√ß√£o dos dados brutos para uma vers√£o refinada e estruturada, pronta para explora√ß√£o anal√≠tica. A partir daqui, as an√°lises ganham maior precis√£o e confiabilidade, com base em dados limpos e bem organizados.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df91b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deletando dados da tabela: olist_order_payments\n",
      "Dados da tabela olist_order_payments apagados com sucesso.\n",
      "Deletando dados da tabela: olist_order_items\n",
      "Dados da tabela olist_order_items apagados com sucesso.\n",
      "Deletando dados da tabela: olist_order_reviews\n",
      "Dados da tabela olist_order_reviews apagados com sucesso.\n",
      "Deletando dados da tabela: olist_orders\n",
      "Dados da tabela olist_orders apagados com sucesso.\n",
      "Deletando dados da tabela: olist_products\n",
      "Dados da tabela olist_products apagados com sucesso.\n",
      "Deletando dados da tabela: olist_sellers\n",
      "Dados da tabela olist_sellers apagados com sucesso.\n",
      "Deletando dados da tabela: olist_customers\n",
      "Dados da tabela olist_customers apagados com sucesso.\n",
      "Deletando dados da tabela: olist_geolocation\n",
      "Dados da tabela olist_geolocation apagados com sucesso.\n",
      "Inserindo dados limpos para a tabela: olist_geolocation\n",
      "Dados limpos inseridos na tabela olist_geolocation com sucesso.\n",
      "\n",
      "Inserindo dados limpos para a tabela: olist_customers\n",
      "Dados limpos inseridos na tabela olist_customers com sucesso.\n",
      "\n",
      "Inserindo dados limpos para a tabela: olist_sellers\n",
      "Dados limpos inseridos na tabela olist_sellers com sucesso.\n",
      "\n",
      "Inserindo dados limpos para a tabela: olist_products\n",
      "Dados limpos inseridos na tabela olist_products com sucesso.\n",
      "\n",
      "Inserindo dados limpos para a tabela: olist_orders\n",
      "Dados limpos inseridos na tabela olist_orders com sucesso.\n",
      "\n",
      "Inserindo dados limpos para a tabela: olist_order_items\n",
      "Removidos 24 registros inv√°lidos da tabela olist_order_items por order_id inexistente.\n",
      "Dados limpos inseridos na tabela olist_order_items com sucesso.\n",
      "\n",
      "Inserindo dados limpos para a tabela: olist_order_payments\n",
      "Removidos 23 registros inv√°lidos da tabela olist_order_payments por order_id inexistente.\n",
      "Dados limpos inseridos na tabela olist_order_payments com sucesso.\n",
      "\n",
      "Inserindo dados limpos para a tabela: olist_order_reviews\n",
      "Removidos 23 registros inv√°lidos da tabela olist_order_reviews por order_id inexistente.\n",
      "Dados limpos inseridos na tabela olist_order_reviews com sucesso.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Caminho base onde est√£o localizados os arquivos CSV com dados limpos\n",
    "base_path_limpos = \"C:/Users/Pasta/Olist/Dados/\"\n",
    "\n",
    "# Cria√ß√£o do engine para conex√£o com o banco MySQL local\n",
    "engine = create_engine(\"mysql+mysqlconnector://root:...\")\n",
    "\n",
    "\n",
    "# Dicion√°rio que mapeia o nome das tabelas no banco para os respectivos arquivos CSV\n",
    "tabelas_arquivos = {\n",
    "    \"olist_geolocation\": \"olist_geolocation.csv\",\n",
    "    \"olist_customers\": \"olist_customers.csv\",\n",
    "    \"olist_sellers\": \"olist_sellers.csv\",\n",
    "    \"olist_products\": \"olist_products.csv\",\n",
    "    \"olist_orders\": \"olist_orders.csv\",\n",
    "    \"olist_order_items\": \"olist_order_items.csv\",\n",
    "    \"olist_order_payments\": \"olist_order_payments.csv\",\n",
    "    \"olist_order_reviews\": \"olist_order_reviews.csv\"\n",
    "}\n",
    "\n",
    "\n",
    "# Ordem correta de exclus√£o de dados das tabelas, respeitando depend√™ncias de chaves estrangeiras\n",
    "ordem_exclusao = [\n",
    "    \"olist_order_payments\",\n",
    "    \"olist_order_items\",\n",
    "    \"olist_order_reviews\",\n",
    "    \"olist_orders\",\n",
    "    \"olist_products\",\n",
    "    \"olist_sellers\",\n",
    "    \"olist_customers\",\n",
    "    \"olist_geolocation\"\n",
    "]\n",
    "\n",
    "\n",
    "# Ordem correta de inser√ß√£o dos dados nas tabelas, do dado mais independente ao mais dependente\n",
    "ordem_insercao = [\n",
    "    \"olist_geolocation\",\n",
    "    \"olist_customers\",\n",
    "    \"olist_sellers\",\n",
    "    \"olist_products\",\n",
    "    \"olist_orders\",\n",
    "    \"olist_order_items\",\n",
    "    \"olist_order_payments\",\n",
    "    \"olist_order_reviews\"\n",
    "]\n",
    "\n",
    "# Desativar verifica√ß√£o de chaves estrangeiras para permitir truncamento em cascata\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(\"SET FOREIGN_KEY_CHECKS = 0;\"))\n",
    "    \n",
    "    # Exclui os dados das tabelas seguindo a ordem de depend√™ncia\n",
    "    for tabela in ordem_exclusao:\n",
    "        print(f\"Deletando dados da tabela: {tabela}\")\n",
    "        conn.execute(text(f\"DELETE FROM {tabela};\"))\n",
    "        print(f\"Dados da tabela {tabela} apagados com sucesso.\")\n",
    "    \n",
    "    # Reativa verifica√ß√£o de chaves estrangeiras\n",
    "    conn.execute(text(\"SET FOREIGN_KEY_CHECKS = 1;\"))\n",
    "\n",
    "# Carrega os pedidos (orders) para filtrar posteriormente as tabelas que dependem de order_id\n",
    "df_orders = pd.read_csv(base_path_limpos + tabelas_arquivos[\"olist_orders\"])\n",
    "order_ids_validos = set(df_orders[\"order_id\"])\n",
    "\n",
    "# La√ßo principal para carregar e inserir os dados limpos em cada tabela\n",
    "for tabela in ordem_insercao:\n",
    "    print(f\"Inserindo dados limpos para a tabela: {tabela}\")\n",
    "    \n",
    "    # Caminho completo do arquivo CSV da tabela atual\n",
    "    caminho_completo = base_path_limpos + tabelas_arquivos[tabela]\n",
    "    \n",
    "    # Leitura do CSV\n",
    "    df = pd.read_csv(caminho_completo)\n",
    "\n",
    "    # Filtra registros inv√°lidos por order_id, se a tabela depender dessa chave estrangeira\n",
    "    if tabela in [\"olist_order_items\", \"olist_order_payments\", \"olist_order_reviews\"]:\n",
    "        qtde_antes = len(df)\n",
    "        df = df[df[\"order_id\"].isin(order_ids_validos)]\n",
    "        qtde_filtrados = qtde_antes - len(df)\n",
    "        if qtde_filtrados > 0:\n",
    "            print(f\"Removidos {qtde_filtrados} registros inv√°lidos da tabela {tabela} por order_id inexistente.\")\n",
    "\n",
    "    # Inser√ß√£o dos dados no banco de dados (modo append)\n",
    "    df.to_sql(\n",
    "        name=tabela,\n",
    "        con=engine,\n",
    "        if_exists='append',\n",
    "        index=False,\n",
    "        chunksize=500  # Inser√ß√£o em blocos de 500 linhas para otimizar performance\n",
    "    )\n",
    "    \n",
    "    print(f\"Dados limpos inseridos na tabela {tabela} com sucesso.\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
