{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1136e3e",
   "metadata": {},
   "source": [
    "**T√≥picos do Notebook**<a id='toc0_'></a>\n",
    "\n",
    "- [üõ†Ô∏è Pr√©-Processamento e Tratamento dos Dados](#toc1_)\n",
    "- [Importa√ß√µes e Extra√ß√£o dos Dados](#toc2_)\n",
    "- [Tratamento dos Dados](#toc3_)\n",
    "  - [Tabela: olist_geolocation](#toc3_1_)\n",
    "  - [Tabela: olist_customers](#toc3_2_)\n",
    "  - [Tabela: olist_sellers](#toc3_3_)\n",
    "  - [Tabela: olist_products](#toc3_4_)\n",
    "  - [Tabela: olist_orders](#toc3_5_)\n",
    "  - [Tabela: olist_order_items](#toc3_6_)\n",
    "  - [Tabela: olist_order_payments](#toc3_7_)\n",
    "  - [Tabela: olist_order_reviews](#toc3_8_)\n",
    "  - [Salvando os Dados Limpos](#toc3_9_)\n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a940659",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[üõ†Ô∏è Pr√©-Processamento e Tratamento dos Dados](#toc0_)\n",
    "\n",
    "**Este notebook re√∫ne todas as etapas de limpeza, corre√ß√£o e padroniza√ß√£o dos dados, com base nos problemas diagnosticados na An√°lise Explorat√≥ria de Dados ‚Äî Parte 1.**\n",
    "\n",
    "üîß Os procedimentos abordados incluem:\n",
    "\n",
    "- Identifica√ß√£o e tratamento de valores nulos ou inconsistentes\n",
    "- Padroniza√ß√£o de tipos de dados\n",
    "- Normaliza√ß√£o de formatos (datas, textos, etc.)\n",
    "- Corre√ß√£o de duplicatas, outliers e registros fora do padr√£o\n",
    "- Ajustes espec√≠ficos em colunas como CEP, categorias de produto e avalia√ß√µes dos clientes\n",
    "\n",
    "‚öôÔ∏è Ao final desta etapa, os datasets estar√£o preparados e confi√°veis, prontos para an√°lises aprofundadas e gera√ß√£o de conhecimento a partir dos dados.\n",
    "\n",
    "> A qualidade dos dados √© a base de qualquer estudo relevante ‚Äî este notebook √© dedicado a garantir que essa funda√ß√£o seja s√≥lida e transparente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Importa√ß√µes e Extra√ß√£o dos Dados](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77467825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Biblioteca para leitura e manipula√ß√£o de dados tabulares\n",
    "import numpy as np  # Biblioteca para opera√ß√µes num√©ricas e estat√≠sticas\n",
    "import matplotlib.pyplot as plt  # Biblioteca para gera√ß√£o de gr√°ficos b√°sicos (visualiza√ß√£o inicial dos dados)\n",
    "import seaborn as sns  # Biblioteca para gr√°ficos estat√≠sticos mais avan√ßados e visualmente atraentes\n",
    "import unicodedata # Para padroniza√ß√£o dos Dados\n",
    "import unidecode # Para padroniza√ß√£o dos Dados\n",
    "from rapidfuzz import process, fuzz # Para corre√ß√£o de dados\n",
    "from sqlalchemy import create_engine # Utilizada para criar uma conex√£o com bancos de dados SQL (ex: MySQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b6169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estabelecendo conex√£o com o banco de dados MySQL usando SQLAlchemy\n",
    "\n",
    "conn = create_engine(\"mysql+mysqlconnector://root:...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bf510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra√ß√£o completa das tabelas do banco de dados para an√°lise em pandas\n",
    "olist_geolocation = pd.read_sql(\n",
    "    \"SELECT * FROM olist_geolocation\", con=conn)\n",
    "\n",
    "olist_customers = pd.read_sql(\n",
    "    \"SELECT * FROM olist_customers\", con=conn)\n",
    "\n",
    "olist_sellers = pd.read_sql(\n",
    "    \"SELECT * FROM olist_sellers\", con=conn)\n",
    "\n",
    "olist_products = pd.read_sql(\n",
    "    \"SELECT * FROM olist_products\", con=conn)\n",
    "\n",
    "olist_orders = pd.read_sql(\n",
    "    \"SELECT * FROM olist_orders\", con=conn)\n",
    "\n",
    "olist_order_items = pd.read_sql(\n",
    "    \"SELECT * FROM olist_order_items\", con=conn)\n",
    "\n",
    "olist_order_payments = pd.read_sql(\n",
    "    \"SELECT * FROM olist_order_payments\", con=conn)\n",
    "\n",
    "olist_order_reviews = pd.read_sql(\n",
    "    \"SELECT * FROM olist_order_reviews\", con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3eb63c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000163, 5),\n",
       " (99441, 5),\n",
       " (3095, 4),\n",
       " (32951, 9),\n",
       " (99441, 8),\n",
       " (112650, 7),\n",
       " (103886, 5),\n",
       " (99224, 7))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tamanho das tabelas pr√©-tratamento\n",
    "olist_geolocation.shape, olist_customers.shape, olist_sellers.shape, olist_products.shape, olist_orders.shape, olist_order_items.shape, olist_order_payments.shape, olist_order_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Tratamento dos Dados](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "953268c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o para padronizar as colunas de data das tabelas,\n",
    "# convertendo para datetime (se poss√≠vel) e removendo a parte da hora.\n",
    "def remover_hora_das_datas(df):\n",
    "    \"\"\"\n",
    "    Remove a parte de hora das colunas de data em um DataFrame, deixando apenas a data (formato AAAA-MM-DD).\n",
    "    \n",
    "    Par√¢metros:\n",
    "    df (pd.DataFrame): DataFrame que cont√©m colunas de data com ou sem hora.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: As primeiras 2 linhas do DataFrame com as datas normalizadas.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        # Verifica se a coluna j√° √© do tipo datetime\n",
    "        if pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            # Remove a hora, mantendo apenas a data (00:00:00)\n",
    "            df[col] = df[col].dt.normalize()\n",
    "            \n",
    "        # Caso a coluna seja do tipo objeto (string), tenta convert√™-la para datetime\n",
    "        elif df[col].dtype == object:\n",
    "            try:\n",
    "                # Tenta converter a coluna para datetime e remover a hora\n",
    "                df[col] = pd.to_datetime(df[col], errors='raise').dt.normalize()\n",
    "            except:\n",
    "                # Ignora colunas que n√£o podem ser convertidas para datetime\n",
    "                pass\n",
    "            \n",
    "    # Retorna as duas primeiras linhas para visualiza√ß√£o r√°pida da transforma√ß√£o\n",
    "    return df.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Tabela: olist_geolocation](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b50cb3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados restantes: (726819, 5)\n"
     ]
    }
   ],
   "source": [
    "# Remove registros duplicados do DataFrame \"olist_geolocation\"\n",
    "olist_geolocation = olist_geolocation.drop_duplicates()\n",
    "\n",
    "# Exibe a quantidade de dados restantes ap√≥s a remo√ß√£o dos duplicados\n",
    "print(f'Dados restantes: {olist_geolocation.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7710986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte os dados da coluna 'geolocation_zip_code_prefix' de string (object) para inteiro (int)\n",
    "olist_geolocation[\"geolocation_zip_code_prefix\"] = olist_geolocation[\"geolocation_zip_code_prefix\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc3_1_1_'></a>[Coluna \"geolocation_city\"](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09b1ce21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cidades √∫nicas (padronizadas): 5967\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para remover acentos de textos (ex: \"S√£o Paulo\" ‚Üí \"Sao Paulo\")\n",
    "def remover_acentos(texto):\n",
    "    return unicodedata.normalize('NFKD', str(texto)).encode('ASCII', 'ignore').decode('utf-8')\n",
    "\n",
    "# Padronizando os nomes das cidades:\n",
    "# - Convertendo para min√∫sculas\n",
    "# - Removendo espa√ßos extras\n",
    "# - Eliminando acentos\n",
    "olist_geolocation['geolocation_city'] = (\n",
    "    olist_geolocation['geolocation_city']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .apply(remover_acentos)\n",
    ")\n",
    "\n",
    "# Conferindo resultado\n",
    "print(\"Cidades √∫nicas (padronizadas):\", olist_geolocation['geolocation_city'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f811a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio de mapeamento para padroniza√ß√£o de nomes de cidades com abrevia√ß√µes, erros ou codifica√ß√µes incorretas\n",
    "mapeamento_cidades = {\n",
    "    # Abrevia√ß√µes encontradas na EDA\n",
    "    'sp': 'sao paulo',\n",
    "    'rj': 'rio de janeiro',\n",
    "    'bh': 'belo horizonte',\n",
    "    \n",
    "    # Corre√ß√µes de nomes com s√≠mbolos, n√∫meros ou codifica√ß√µes\n",
    "    '4¬∫ centenario': 'quarto centenario',\n",
    "    '4o. centenario': 'quarto centenario',\n",
    "    'sao joao do pau d%26apos%3balho': \"sao joao do pau d'alho\",\n",
    "    'lambari d%26apos%3boeste': \"lambari d'oeste\",\n",
    "    'riacho fundo 2': 'riacho fundo ii',\n",
    "}\n",
    "\n",
    "# Aplicando as corre√ß√µes de nomes\n",
    "olist_geolocation['geolocation_city'] = (\n",
    "    olist_geolocation['geolocation_city']\n",
    "    .replace(mapeamento_cidades)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dd6e522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5961"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conta o n√∫mero de cidades √∫nicas na coluna 'geolocation_city' ap√≥s as padroniza√ß√µes\n",
    "# Espera-se que o resultado seja no m√°ximo 5570, que √© o total oficial de munic√≠pios brasileiros\n",
    "olist_geolocation['geolocation_city'].nunique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc3_1_1_1_'></a>[Tratando os erros de escritas no nome das cidades](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876182ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega arquivo CSV contendo a lista oficial de cidades brasileiras do IBGE\n",
    "# L√™ apenas a coluna 'MUNIC√çPIO - TOM', unica necess√°ria para verifica√ß√£o\n",
    "df_ibge = pd.read_csv(\n",
    "    \"C:/Users/Pasta/municipios.csv\",\n",
    "    sep=';',\n",
    "    encoding='latin1',\n",
    "    usecols=['MUNIC√çPIO - TOM']  # Apenas a coluna com nomes das cidades ser√° importada\n",
    ")\n",
    "\n",
    "# Renomeia a coluna para facilitar manipula√ß√£o e padroniza os nomes das cidades\n",
    "df_ibge.rename(columns={'MUNIC√çPIO - TOM': 'cidade_oficial'}, inplace=True)\n",
    "\n",
    "# Cria nova coluna com nomes normalizados: min√∫sculas, sem espa√ßos extras e sem acentos\n",
    "df_ibge['cidade_oficial_normalizada'] = (\n",
    "    df_ibge['cidade_oficial']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .apply(remover_acentos)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1716016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aplicando fuzzy\n",
      "Fuzzy aplicado\n",
      "Criando mapeamento...\n",
      "Recolocando acentos...\n"
     ]
    }
   ],
   "source": [
    "# Fun√ß√£o para corrigir nomes de cidades via fuzzy matching\n",
    "# Recebe um nome de cidade e uma lista de cidades oficiais normalizadas\n",
    "# Retorna a melhor correspond√™ncia com score ‚â• 85, caso contr√°rio None\n",
    "def corrigir_cidade(cidade, cidades_oficiais):\n",
    "    match, score, _ = process.extractOne(cidade, cidades_oficiais, scorer=fuzz.ratio)\n",
    "    return match if score >= 85 else None\n",
    "\n",
    "print('Aplicando fuzzy')\n",
    "\n",
    "# Aplicando a fun√ß√£o de corre√ß√£o para cada cidade da base, substituindo pelo nome normalizado mais pr√≥ximo na lista oficial do IBGE\n",
    "olist_geolocation['geolocation_city'] = olist_geolocation['geolocation_city'].apply(\n",
    "    lambda x: corrigir_cidade(x, df_ibge['cidade_oficial_normalizada'].tolist())\n",
    ")\n",
    "\n",
    "print('Fuzzy aplicado')\n",
    "print('Criando mapeamento...')\n",
    "\n",
    "# Cria um dicion√°rio que mapeia nomes normalizados para seus nomes oficiais com acentua√ß√£o correta\n",
    "mapa_para_nome_certo = dict(zip(df_ibge['cidade_oficial_normalizada'], df_ibge['cidade_oficial']))\n",
    "\n",
    "print('Recolocando acentos...')\n",
    "\n",
    "# Substitui os nomes normalizados pela grafia oficial com acentos, recuperando a escrita correta\n",
    "olist_geolocation['geolocation_city'] = olist_geolocation['geolocation_city'].map(mapa_para_nome_certo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511456a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 726819 entries, 0 to 1000161\n",
      "Series name: geolocation_city\n",
      "Non-Null Count   Dtype \n",
      "--------------   ----- \n",
      "724489 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Informa√ß√µes da coluna p√≥s tratamento\n",
    "olist_geolocation['geolocation_city'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e479b71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui valores nulos (cidades n√£o reconhecidas pelo fuzzy matching) pelo r√≥tulo padr√£o 'Cidade Desconhecida'\n",
    "olist_geolocation['geolocation_city'] = olist_geolocation['geolocation_city'].fillna('Cidade Desconhecida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Tabela: olist_customers](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28c877dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a coluna 'customer_zip_code_prefix' do tipo object (string) para inteiro (int)\n",
    "olist_customers['customer_zip_code_prefix'] = olist_customers['customer_zip_code_prefix'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_3_'></a>[Tabela: olist_sellers](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60db8071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte a coluna 'seller_zip_code_prefix' do tipo object (string) para inteiro (int)\n",
    "olist_sellers['seller_zip_code_prefix'] = olist_sellers['seller_zip_code_prefix'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "439f0b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corre√ß√£o manual de valor incorreto na coluna 'seller_city':\n",
    "# Foi identificado que o registro com valor num√©rico '04482255' corresponde ao CEP do Rio de Janeiro,\n",
    "# ent√£o substitui esse valor pelo nome correto da cidade para garantir consist√™ncia nos dados.\n",
    "olist_sellers['seller_city'] = olist_sellers['seller_city'].replace('04482255', 'rio de janeiro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a488b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padronizando os nomes das cidades dos vendedores:\n",
    "# - Convertendo para min√∫sculas\n",
    "# - Removendo espa√ßos extras\n",
    "# - Eliminando acentos\n",
    "olist_sellers['seller_city'] = (\n",
    "    olist_sellers['seller_city']\n",
    "    .str.lower()\n",
    "    .str.strip()\n",
    "    .apply(remover_acentos)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a94ff564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicion√°rio de mapeamento para padroniza√ß√£o de nomes de cidades com abrevia√ß√µes, erros ou codifica√ß√µes incorretas\n",
    "mapeamento_cidades = {\n",
    "    # Abrevia√ß√µes encontradas na EDA\n",
    "    'sp': 'sao paulo',\n",
    "    'sbc': 'sao bernardo do campo'\n",
    "}\n",
    "\n",
    "# Aplicando as corre√ß√µes de nomes\n",
    "olist_sellers['seller_city'] = (\n",
    "    olist_sellers['seller_city']\n",
    "    .replace(mapeamento_cidades)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11c6bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a fun√ß√£o de corre√ß√£o para cada cidade da base, substituindo pelo nome normalizado mais pr√≥ximo na lista oficial do IBGE\n",
    "olist_sellers['seller_city'] = olist_sellers['seller_city'].apply(\n",
    "    lambda x: corrigir_cidade(x, df_ibge['cidade_oficial_normalizada'].tolist())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91e0dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitui valores nulos (cidades n√£o reconhecidas pelo fuzzy matching) pelo r√≥tulo padr√£o 'Cidade Desconhecida'\n",
    "olist_sellers['seller_city'] = olist_sellers['seller_city'].fillna('Cidade Desconhecida')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_4_'></a>[Tabela: olist_products](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substituindo valores ausentes (NaN) na coluna 'product_category_name' por 'N√£o Definido'\n",
    "# Isso evita problemas em an√°lises e modelagens que n√£o aceitam valores nulos\n",
    "olist_products['product_category_name'].fillna('N√£o Definido', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdf91602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona apenas as colunas essenciais para a an√°lise:\n",
    "# - 'product_id' para identifica√ß√£o do produto\n",
    "# - 'product_category_name' para classifica√ß√£o do produto\n",
    "olist_products = olist_products[['product_id', 'product_category_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_5_'></a>[Tabela: olist_orders](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6974391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifique as colunas de data que podem ter valores nulos\n",
    "colunas_data = ['order_purchase_timestamp', 'order_approved_at', \n",
    "                'order_delivered_carrier_date', 'order_delivered_customer_date']\n",
    "\n",
    "# Filtrar as linhas onde o status √© \"delivered\" e h√° pelo menos um NaT em colunas de data\n",
    "condicao = (olist_orders['order_status'] == 'delivered') & (olist_orders[colunas_data].isnull().any(axis=1))\n",
    "\n",
    "# Remove essas linhas (obrigatoriamente todas as datas de pedidos entregue (\"order_status\" = \"delivered\" precisam estar preenchidas))\n",
    "olist_orders = olist_orders[~condicao]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b3ff9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduzindo os status dos pedidos para melhor compreens√£o\n",
    "\n",
    "# Dicion√°rio de tradu√ß√£o dos status\n",
    "traducao_status = {\n",
    "    'delivered': 'entregue',\n",
    "    'shipped': 'enviado',\n",
    "    'canceled': 'cancelado',\n",
    "    'unavailable': 'indispon√≠vel',\n",
    "    'invoiced': 'faturado',\n",
    "    'processing': 'em processamento',\n",
    "    'created': 'criado',\n",
    "    'approved': 'aprovado'\n",
    "}\n",
    "\n",
    "# Aplicar a tradu√ß√£o na coluna\n",
    "olist_orders['order_status'] = olist_orders['order_status'].replace(traducao_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1afa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo a parte de hora das colunas datetime do DataFrame 'olist_orders', mantendo apenas a data\n",
    "remover_hora_das_datas(olist_orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_6_'></a>[Tabela: olist_order_items](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12c4ddcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo registros com shipping_limit_date fora do intervalo esperado (apenas 4, em 2020)\n",
    "# Justificativa: A base de dados concentra pedidos entre 2016 e 2018, portanto 2020 √© considerado outlier temporal.\n",
    "olist_order_items = olist_order_items[olist_order_items['shipping_limit_date'].dt.year != 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo a parte de hora das colunas datetime do DataFrame 'olist_order_items', mantendo apenas a data\n",
    "remover_hora_das_datas(olist_order_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_7_'></a>[Tabela: olist_order_payments](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f55a1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputa√ß√£o dos valores zerados na coluna 'payment_installments':\n",
    "# - Calcula a m√©dia dos valores positivos (maiores que zero) para evitar distor√ß√£o causada por zeros\n",
    "# - Arredonda a m√©dia para facilitar o entendimento e manuten√ß√£o dos dados\n",
    "# - Substitui os valores iguais a zero pela m√©dia calculada, tratando poss√≠veis registros incorretos ou ausentes\n",
    "media_parcelas = olist_order_payments.loc[olist_order_payments['payment_installments'] > 0, 'payment_installments'].mean()\n",
    "media_parcelas = round(media_parcelas)\n",
    "\n",
    "olist_order_payments['payment_installments'] = olist_order_payments['payment_installments'].replace(0, media_parcelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84b10fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputa√ß√£o dos valores zerados na coluna 'payment_value':\n",
    "# - Calcula a m√©dia dos valores positivos (maiores que zero) para evitar distor√ß√£o causada por zeros\n",
    "# - Arredonda a m√©dia para facilitar o entendimento e manuten√ß√£o dos dados\n",
    "# - Substitui os valores iguais a zero pela m√©dia calculada, tratando poss√≠veis registros incorretos ou ausentes\n",
    "\n",
    "media_valor = olist_order_payments.loc[olist_order_payments['payment_value'] > 0, 'payment_value'].mean()\n",
    "media_valor = round(media_valor)\n",
    "\n",
    "olist_order_payments['payment_value'] = olist_order_payments['payment_value'].replace(0, media_valor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d519813c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifica o valor mais frequente (moda) na coluna 'payment_type', que ser√° usado para corre√ß√£o\n",
    "moda_pagamento = olist_order_payments['payment_type'].mode()[0]\n",
    "\n",
    "# Substitui os valores n√£o definidos ('not_defined') pela moda calculada,\n",
    "# garantindo que a coluna n√£o contenha categorias inv√°lidas\n",
    "olist_order_payments['payment_type'] = olist_order_payments['payment_type'].replace('not_defined', moda_pagamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_8_'></a>[Tabela: olist_order_reviews](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo a parte de hora das colunas datetime do DataFrame 'olist_order_reviews', mantendo apenas a data\n",
    "remover_hora_das_datas(olist_order_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a1864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Criando um DataFrame apenas com os coment√°rios para an√°lise de sentimento.\n",
    "\n",
    "Algumas avalia√ß√µes possuem apenas o t√≠tulo ou apenas a mensagem ‚Äî poucas t√™m os dois preenchidos.\n",
    "Portanto, para aproveitar ao m√°ximo os dados dispon√≠veis, os dois campos ser√£o combinados em uma √∫nica coluna.\n",
    "\n",
    "Entretanto, se ambos os campos forem nulos, consideramos que n√£o h√° coment√°rio √∫til para an√°lise e marcaremos como `NaN`.\n",
    "Isso √© importante para garantir que a coluna `full_review_text` represente fielmente a exist√™ncia (ou n√£o) de um coment√°rio.\n",
    "\n",
    "As colunas `review_id` e `order_id` ser√£o mantidas para rastreabilidade do coment√°rio e poss√≠veis an√°lises cruzadas.\n",
    "\"\"\"\n",
    "\n",
    "# Inicializa um novo DataFrame vazio para armazenar os coment√°rios e dados relacionados\n",
    "comentarios = pd.DataFrame()\n",
    "\n",
    "# Copia as colunas necess√°rias do DataFrame original\n",
    "comentarios[\"review_id\"] = olist_order_reviews[\"review_id\"]\n",
    "comentarios[\"order_id\"] = olist_order_reviews[\"order_id\"]\n",
    "comentarios[\"review_score\"] = olist_order_reviews[\"review_score\"]\n",
    "\n",
    "# Cria uma m√°scara booleana onde tanto o t√≠tulo quanto a mensagem s√£o nulos\n",
    "ambos_nulos = (\n",
    "    olist_order_reviews[\"review_comment_title\"].isna() & \n",
    "    olist_order_reviews[\"review_comment_message\"].isna()\n",
    ")\n",
    "\n",
    "# Concatena os campos de t√≠tulo e mensagem, tratando nulos como strings vazias\n",
    "comentarios[\"full_review_text\"] = (\n",
    "    olist_order_reviews[\"review_comment_title\"].fillna(\"\") + \" \" +\n",
    "    olist_order_reviews[\"review_comment_message\"].fillna(\"\")\n",
    ").str.strip()\n",
    "\n",
    "# Onde ambos os campos eram nulos, substitui o texto combinado por np.nan\n",
    "comentarios.loc[ambos_nulos, \"full_review_text\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26fc8dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99224 entries, 0 to 99223\n",
      "Data columns (total 4 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   review_id         99224 non-null  object\n",
      " 1   order_id          99224 non-null  object\n",
      " 2   review_score      99224 non-null  int64 \n",
      " 3   full_review_text  42706 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 3.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# An√°lise da tabela: tipos de dados, quantidade de entradas, valores nulos\n",
    "comentarios.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf95ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove os registros sem coment√°rio (valores nulos em full_review_text)\n",
    "# Na an√°lise de sentimento, s√≥ faz sentido trabalhar com textos existentes.\n",
    "# Portanto, aqui estamos filtrando apenas as linhas que possuem algum conte√∫do v√°lido para an√°lise.\n",
    "comentarios = comentarios.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_9_'></a>[Salvando os Dados Limpos](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba437b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporta√ß√£o dos DataFrames tratados para arquivos CSV (sem o √≠ndice do pandas)\n",
    "\n",
    "# olist_geolocation.to_csv(\"olist_geolocation.csv\", index=False)\n",
    "# olist_customers.to_csv(\"olist_customers.csv\", index=False)\n",
    "# olist_sellers.to_csv(\"olist_sellers.csv\", index=False)\n",
    "# olist_products.to_csv(\"olist_products.csv\", index=False)\n",
    "# olist_orders.to_csv(\"olist_orders.csv\", index=False)\n",
    "# olist_order_items.to_csv(\"olist_order_items.csv\", index=False)\n",
    "# olist_order_payments.to_csv(\"olist_order_payments.csv\", index=False)\n",
    "# olist_order_reviews.to_csv(\"olist_order_reviews.csv\", index=False)\n",
    "# comentarios.to_csv(\"comentarios.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
